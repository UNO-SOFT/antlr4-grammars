// maketest creates the test and example files for the given grammar.
package main

import (
	"bramp.net/antlr4-grammars/internal"
	"fmt"
	"github.com/iancoleman/strcase"
	"log"
	"os"
	"os/exec"
	"path/filepath"
	"strings"
	"text/template"
)

const GRAMMARS_ROOT = "grammars-v4"

// TESTFILE is the template for a go test file for this grammar.
// It expects to be executed with a pom.
const TESTFILE = `// Package {{ .Name }}_test contains tests for the {{ .LongName }} grammar.
// The tests should be run with the -timeout flag, to ensure the parser doesn't
// get stuck.
//
// Do not edit this file, it is generated by maketest.go
//
package {{ .PackageName }}_test

import (
	"bramp.net/antlr4-grammars/{{.PackageName}}"
{{- if or (eq .CaseInsensitiveType "UPPER") (eq .CaseInsensitiveType "lower") }}
	"bramp.net/antlr4-grammars/internal"
{{- end }}
	"fmt"
	"github.com/antlr/antlr4/runtime/Go/antlr"
	"path/filepath"
	"testing"
)

const MAX_TOKENS = 1000000

var examples = []string{
{{- range $_, $example := .Examples }}
	{{ printf "%q" . }},
{{- end }}
}

type exampleListener struct {
	*{{.PackageName}}.Base{{ .ListenerName }}
}

func (l *exampleListener) EnterEveryRule(ctx antlr.ParserRuleContext) {
	fmt.Println(ctx.GetText())
}

func Example() {
	// Setup the input
	is := antlr.NewInputStream("...some text to parse...")

	// Create the Lexer
	lexer := {{.PackageName}}.New{{ .LexerName }}(is)
	stream := antlr.NewCommonTokenStream(lexer, antlr.TokenDefaultChannel)

	// Create the Parser
	p := {{.PackageName}}.New{{ .ParserName }}(stream)
	p.BuildParseTrees = true
	p.AddErrorListener(antlr.NewDiagnosticErrorListener(true))

	// Finally walk the tree
	tree := p.{{ .EntryPoint | Title }}()
	antlr.ParseTreeWalkerDefault.Walk(&exampleListener{}, tree)
}

func newCharStream(filename string) (antlr.CharStream, error) {
	var input antlr.CharStream
	input, err := antlr.NewFileStream(filepath.Join("..", filename))
	if err != nil {
		return nil, err
	}

	{{ if eq .CaseInsensitiveType "UPPER" }}
	// TODO Switch NewCaseChangingStream for something in the core antlr
	input = internal.NewCaseChangingStream(input, true)
	{{ else if eq .CaseInsensitiveType "lower" }}
	input = internal.NewCaseChangingStream(input, false)
	{{ end -}}

	return input, nil
}

func Test{{ .LexerName }}(t *testing.T) {
	for _, file := range examples {
		input, err := newCharStream(file)
		if err != nil {
			t.Errorf("Failed to open example file: %s", err)
		}

		// Create the Lexer
		lexer := {{.PackageName}}.New{{ .LexerName }}(input)

		// Try and read all tokens
		i := 0
		for ; i < MAX_TOKENS; i++ {
			t := lexer.NextToken()
			if t.GetTokenType() == antlr.TokenEOF {
				break
			}
		}

		// If we read too many tokens, then perhaps there is a problem with the lexer.
		if i == MAX_TOKENS {
			t.Errorf("New{{ .LexerName }}(%q) read %d tokens without finding EOF", file, i)
		}
	}
}

func Test{{ .ParserName }}(t *testing.T) {
	// TODO(bramp): Run this test with and without p.BuildParseTrees

	for _, file := range examples {
		input, err := newCharStream(file)
		if err != nil {
			t.Errorf("Failed to open example file: %s", err)
		}

		// Create the Lexer
		lexer := {{.PackageName}}.New{{ .LexerName }}(input)
		stream := antlr.NewCommonTokenStream(lexer, antlr.TokenDefaultChannel)

		// Create the Parser
		p := {{.PackageName}}.New{{ .ParserName }}(stream)
		p.BuildParseTrees = true
		p.AddErrorListener(antlr.NewDiagnosticErrorListener(true)) // TODO Change this
		p.AddErrorListener(antlr.NewConsoleErrorListener())

		// Finally test
		p.{{ .EntryPoint | Title }}()

		// TODO Check for errors
	}
}
`

// fuzzyMatch returns a filename that matches either exactly, or close enough
// // to the input. Due to the way the Makefile is constructed, and that the
// directory names may not match the package name. So we do this hack.
func fuzzyMatch(filename string) (string, error) {
	filename = strings.Replace(filename, "_", "*", -1)
	matches, err := filepath.Glob(filename)
	if err != nil {
		return "", err
	}
	if len(matches) != 1 {
		return "", fmt.Errorf("%d matches, expected only 1", len(matches))
	}
	return matches[0], nil
}

func main() {
	if len(os.Args) < 2 {
		fmt.Fprintf(os.Stderr, "Usage: %s <grammar>\n", filepath.Base(os.Args[0]))
		os.Exit(1)
	}

	grammar := os.Args[1]
	path := filepath.Join(GRAMMARS_ROOT, grammar, "pom.xml")
	path, err := fuzzyMatch(path)
	if err != nil {
		log.Fatalf("Failed to find pom file %q: %s", path, err)
	}

	project, err := internal.ParsePom(path)
	if err != nil {
		log.Fatalf("Failed to read pom file %q: %s", path, err)
	}

	funcs := template.FuncMap{
		"Join":    strings.Join,
		"ToCamel": strcase.ToCamel, // I'd prefer to use ToCamel, but the go target does't do this yet...
		"Title":   strings.Title,
	}

	testTemplate := template.Must(template.New("test").Funcs(funcs).Parse(TESTFILE))

	testfile := filepath.Join(grammar, project.FilePrefix()+"_test.go")
	out, err := os.Create(testfile)
	if err != nil {
		log.Fatalf("failed to create %q: %s", testfile, err)
	}

	if err := testTemplate.Execute(out, project); err != nil {
		log.Fatalf("failed to generate %q: %s", testfile, err)
	}

	cmd := exec.Command("go", "fmt", testfile)
	if err := cmd.Run(); err != nil {
		log.Fatalf("failed to `go fmt`: %s", err)
	}
}
